Thinking1	什么是反向传播中的链式法则			简要说明反向传播中的链式法则（10points）

	
Thinking2	请列举几种常见的激活函数，激活函数有什么作用			简要说明常用的激活函数及作用（10points）	


Thinking3	利用梯度下降法训练神经网络，发现模型loss不变，可能有哪些问题？怎么解决？			能简要说明loss不变的解决方案（10points）	

Thinking1	答：神经网络正向传播的时候，源头稍微抖动一点，经过传播之后，末端将会产生很大的波动。
		在反向传播的时候，使用矩阵相乘的形式，求解隐藏层的误差。权重矩阵在反向传播中扮演着传递误差的作用；
		输出层误差在转置权重矩阵的帮助下，传递到了隐藏层，用来更新与隐藏层相连的权重。每一层依次往前类推，
		所谓链式法则，就是层层传递的累计作用。把每一层的误差求出来。


Thinking2	在多层神经网络中，上层节点的输出和下层节点的输入之间具有一个函数关系，这个函数称为激活函数,
常见的激活函数有sigmoid(),tanh(),ReLu();如果不用激活函数，就相当于激励函数f(x) = x，此时每一层节点的输入都
是上层输出的线性函数，那么无论神经网络有多少层，输出都是输入的线性组合 => 与没有隐藏层效果相当;引入非线性函
数作为激励函数，这样神经网络表达能力会更加强大 => 不再是输入的线性组合，而是几乎可以逼近任意函数;

Thinking3	可能是梯度消失，也可能是梯度爆炸；如果初始化的神经网络权重|w|小于1，当层数增多时，小于1的值不断相乘，最后就导致梯度消失的情况出现同理，当权重|w|过大时，最后大于1的值不断相乘，就会产生梯度爆炸。
		解决方法：调整激活函数，损失函数；调整权重，合适的优化器和学习速率
