Thinking1	常用的文本分类方法都有哪些			简要说明常用的文本分类方法（20points）	


Thinking2	RNN为什么会出现梯度消失			能简要说明RNN梯度消失的原因（20points）	


Thinking1	答：传统算法：k临近、决策树、多层感知器、朴素贝叶斯（包括伯努利贝叶斯、高斯贝叶斯和多项式贝叶斯）、逻辑回归和支持向量机；集成学习算法：随机森林、AdaBoost、lightGBM和xgBoost；深度学习算法：前馈神经网络和LSTM等

Thinking2	答：因为RNN中sigmoid的倒数值是固定的，在[0,0.25]之间，而一旦公式中的w也小于1，那么通过这样的公式连乘之后，最终的梯度就会变得非常小，就造成了梯度消失。