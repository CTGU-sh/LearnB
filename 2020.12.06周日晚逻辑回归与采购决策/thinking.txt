Thinking1	逻辑回归的假设条件是怎样的？
		能简要说明逻辑回归的假设条件（10points）

Thinking2	逻辑回归的损失函数是怎样的？
		能简要说明逻辑回归的损失函数（10points）

Thinking3	逻辑回归如何进行分类？
		能简要说明逻辑回归是如何进行分类的（10points）

Thinking4	为什么在训练中需要将高度相关的特征去掉？
		简要说明为什么要去掉相关度高的特征（10points）

Thinking1	逻辑回归的假设条件：1、数据服从伯努利分布，即二项分布；2、正类的概率由sigmoid函数来计算，负类由1减去sigmoid计算。

Thinking2	见附图

Thinking3	逻辑回归是把采用线性回归的模型，把线性回归的输出作为输入放入到sigmoid函数中，训练出各个特征对应的权重。然后sigmoid
函数大于0.5的为1，小于0.5的为0

Thinking4	因为高度相关的特征具有强烈的重复性，相当于同一个影响因素，不去除不仅会让计算量变大，而且还会影响模型的训练参数。